# CIFAR-10 Image Classifier - Udacity Machine Learning Nanodegree Project

**âš ï¸ This Project was first submitted on September 15, 2024. Later on, it went through some enhancements that are listed below.**

![Python](https://img.shields.io/badge/python-v3.9+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Platform](https://img.shields.io/badge/platform-macOS%20%7C%20Linux%20%7C%20Windows-lightgrey.svg)
![GPU](https://img.shields.io/badge/GPU-CUDA%20%7C%20MPS%20%7C%20CPU-yellow.svg)

## ğŸ¯ Project Overview

This project implements a deep learning solution for the CIFAR-10 image classification challenge as part of the **Udacity Introduction to Machine Learning with PyTorch Nanodegree**. The solution features two distinct CNN architectures designed to achieve high accuracy on the CIFAR-10 dataset while maintaining computational efficiency.

### ğŸ† Key Achievements
- âœ… **Successfully exceeded 70% accuracy requirement** (beating Detectocorp's benchmark)
- ğŸš€ **Implemented two distinct architectures**: Simple CNN and Residual CNN
- âš¡ **Cross-platform GPU acceleration** support (CUDA, MPS, CPU)
- ğŸ“Š **Comprehensive training visualization** and model evaluation
- ğŸ”§ **Production-ready environment setup** with automated conda configuration

## ğŸ“Š Performance Results

| Model | Architecture | Validation Accuracy | Test Accuracy | Parameters |
|-------|-------------|-------------------|---------------|------------|
| Simple CNN | 3-layer CNN + FC | 70%+ | 68%+ | ~2M |
| Residual CNN | ResNet-inspired | 80%+ | 78%+ | ~11M |

## ğŸ—ï¸ Architecture Details

### Simple CNN Model
- **Convolutional Layers**: 3 layers (16â†’32â†’64 filters)
- **Pooling**: MaxPool2d after each conv layer
- **Fully Connected**: 2048â†’1024â†’10 neurons
- **Regularization**: Dropout (0.5)
- **Activation**: ReLU + LogSoftmax

### Residual CNN Model
- **Residual Blocks**: 4 layers with skip connections
- **Batch Normalization**: After each convolution
- **Adaptive Pooling**: Global average pooling
- **Channels**: 64â†’128â†’256â†’512 progression
- **Advanced Architecture**: Inspired by ResNet

## ğŸš€ Quick Start

### Prerequisites
- **Anaconda/Miniconda** installed ([Download here](https://docs.conda.io/en/latest/miniconda.html))
- **macOS/Linux/Windows** with Python 3.9+
- **GPU (optional)**: NVIDIA GPU with CUDA or Apple Silicon with MPS

### Setup & Run (One Command)

```bash
# Make setup script executable and run it
chmod +x setup_environment.sh && ./setup_environment.sh

# Activate environment and launch notebook
source ./activate_env.sh
jupyter notebook CIFAR-10_Image_Classifier-STARTER_Solution.ipynb
```

### What the Setup Script Does
- ğŸ” **Auto-detects** your operating system and hardware
- ğŸ“¦ **Creates** a dedicated conda environment (`cifar10-classifier`)
- ğŸ”¥ **Installs PyTorch** with optimal GPU support:
  - **macOS**: MPS acceleration for Apple Silicon
  - **Linux**: CUDA support for NVIDIA GPUs
  - **Windows/Others**: CPU optimized version
- ğŸ“š **Installs** all required packages (matplotlib, numpy, jupyter, tqdm)
- ğŸ”— **Sets up** Jupyter kernel for the environment
- âœ… **Tests** the installation automatically
- ğŸ“ **Creates** activation script for easy future use
- ğŸ’¾ **Exports** environment.yml for reproducibility

### Manual Activation (Future Use)
```bash
# Quick activation
source ./activate_env.sh

# Or manual conda activation
conda activate cifar10-classifier
```

## ğŸ¯ Project Structure

```
python-cifar-10-image-classifier/
â”œâ”€â”€ ğŸ““ CIFAR-10_Image_Classifier-STARTER_Solution.ipynb  # Main project notebook
â”œâ”€â”€ ğŸ”§ setup_environment.sh                      # Complete conda environment setup
â”œâ”€â”€ ğŸ“ activate_env.sh                          # Environment activation script (auto-generated)
â”œâ”€â”€ ğŸ“‹ environment.yml                          # Conda environment specification (auto-generated)
â”œâ”€â”€ ğŸ’¾ cifar10_simple_model.pth                 # Trained simple CNN model
â”œâ”€â”€ ğŸ’¾ cifar10_complex_model.pth                # Trained residual CNN model
â”œâ”€â”€ ğŸ“ CIFAR_10_data/                           # Dataset directory (auto-created)
â”‚   â”œâ”€â”€ cifar-10-python.tar.gz                  # Original dataset
â”‚   â””â”€â”€ cifar-10-batches-py/                    # Extracted data
â”œâ”€â”€ ğŸ“‹ .gitignore                               # Git ignore rules
â”œâ”€â”€ ğŸ“‹ LICENSE                                  # MIT license
â””â”€â”€ ğŸ“‹ README.md                                # This documentation
```

## ğŸ§  Model Training Process

### 1. Data Preprocessing
- **Normalization**: Mean=(0.5, 0.5, 0.5), Std=(0.5, 0.5, 0.5)
- **Augmentation**: Random horizontal flip, rotation (Â±10Â°)
- **Resizing**: 30Ã—30 pixels for consistent input
- **Train/Validation Split**: 80/20 ratio

### 2. Training Configuration
- **Optimizer**: Adam optimizer
- **Loss Function**: Negative Log Likelihood (NLLLoss)
- **Learning Rates**: 0.0005 (Simple), 0.005 (Residual)
- **Early Stopping**: Based on validation accuracy
- **Device Optimization**: Automatic GPU/CPU detection

### 3. Training Features
- **Progress Tracking**: Real-time loss and accuracy monitoring
- **Visualization**: Training curves and validation metrics
- **Model Persistence**: Automatic model saving
- **Performance Analysis**: Comprehensive evaluation metrics

## ğŸ“ˆ Key Enhancements Made

### Original Submission (September 11, 2024)
- âœ… Basic CNN implementation
- âœ… CIFAR-10 data loading and preprocessing
- âœ… Training loop with validation
- âœ… Model evaluation and testing

### Enhanced Version Improvements
1. **ğŸš€ Advanced Architecture**
   - Added Residual CNN with skip connections
   - Implemented batch normalization
   - Enhanced regularization techniques

2. **âš¡ Cross-Platform GPU Support**
   - Comprehensive device detection
   - CUDA support for NVIDIA GPUs
   - MPS support for Apple Silicon
   - Intelligent CPU fallback

3. **ğŸ”§ Production Environment**
   - Automated conda environment setup
   - Cross-platform compatibility script
   - Dependency management
   - Easy activation workflow

4. **ğŸ“Š Enhanced Monitoring**
   - Detailed system information logging
   - GPU memory usage tracking
   - Training progress visualization
   - Performance benchmarking

5. **ğŸ“ Documentation & Usability**
   - Comprehensive README with one-command setup
   - Simplified project structure
   - Performance benchmarks and comparisons
   - Clear setup and usage instructions

6. **ğŸ”§ Streamlined Environment Management**
   - Single script for complete conda environment setup
   - Automatic environment testing and verification
   - Cross-platform compatibility (macOS, Linux, Windows)
   - Auto-generated environment.yml for reproducibility

## ğŸ’¡ Technical Innovation

### Residual Architecture Implementation
```python
class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        # Skip connection implementation for better gradient flow
        # Enables training of deeper networks effectively
```

### Smart Device Detection
```python
def get_optimal_device():
    # Automatic detection of CUDA, MPS, or CPU
    # Cross-platform optimization for maximum performance
```

## ğŸ“ Educational Value

This project demonstrates:
- **Deep Learning Fundamentals**: CNN architecture design
- **PyTorch Proficiency**: Model implementation and training
- **GPU Programming**: Efficient device utilization
- **MLOps Practices**: Environment management and reproducibility
- **Performance Optimization**: Architecture tuning and evaluation

## ğŸ… Comparison to Benchmarks

| Method | Accuracy | Year | Complexity |
|--------|----------|------|------------|
| **Our Residual CNN** | **78%+** | **2024** | **Medium** |
| Detectocorp Benchmark | 70% | - | Unknown |
| Deep Belief Networks | 78.9% | 2010 | High |
| Maxout Networks | 90.6% | 2013 | Very High |
| Wide ResNets | 96.0% | 2016 | Extreme |

## ï¿½ Troubleshooting

### Common Issues

**âŒ "conda: command not found"**
```bash
# Install Miniconda first
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh
```

**âŒ "Permission denied" when running setup script**
```bash
chmod +x setup_environment.sh
./setup_environment.sh
```

**âŒ Environment activation fails**
```bash
# Reload conda
source $(conda info --base)/etc/profile.d/conda.sh
conda activate cifar10-classifier
```

**âŒ GPU not detected**
- **NVIDIA**: Ensure CUDA drivers are installed
- **Apple Silicon**: Update to macOS 12.3+ for MPS support
- **Fallback**: CPU training will work but be slower

## ï¿½ğŸ” Keywords & Tags

`machine-learning` `deep-learning` `computer-vision` `pytorch` `cnn` `image-classification` `cifar10` `udacity` `nanodegree` `residual-networks` `gpu-acceleration` `mps` `cuda` `conda` `automated-setup` `one-command-setup` `jupyter` `python` `neural-networks` `convolutional-neural-networks` `data-science` `artificial-intelligence` `cross-platform`

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Udacity** for providing the comprehensive Machine Learning curriculum
- **PyTorch Team** for the excellent deep learning framework
- **CIFAR-10 Dataset** creators for the benchmark dataset
- **Research Community** for foundational CNN and ResNet architectures

## ğŸ“ Contact

For questions or collaboration opportunities, please reach out through the repository's issue tracker.

---

*Built with â¤ï¸ for the Udacity Machine Learning Nanodegree Program*
